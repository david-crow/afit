\documentclass[../main.tex]{subfiles}
 
\begin{document}

% details of the problem domain/motivate the problem

\IEEEPARstart{A}{n} aircraft's maneuvers in flight are often directly indicated by the plane's roll, pitch, and yaw. Takeoff, for example, can be defined by a high, positive pitch and low, well-correlated values for roll and yaw. Humans, who are naturally error-prone, might misidentify an aircraft's movement when given only a visual observation of the plane. The \ac{usaf} is often concerned with the movement of its various aircraft (and those of other countries), but, in situations without access to the aircraft's flight data (to include roll, pitch, and yaw), the Air Force must rely on human observers. Presently, the \ac{usaf} does not know much about the reliability of non-expert human observers in identifying aircraft maneuvers.

% research objectives

In this research, multiple \ac{ml} models are fit to a set of aircraft characteristics generated by a flight simulator. A non-expert human observer labels each of the simulated observations with the maneuver of the aircraft at that point in time; these labels serve as the model's truth data. We evaluate each model's performance and then identify which model best predicts the aircraft's maneuver. An expert system also labels the observations, and these labels are then compared to those predicted by the best model. In doing so, we can determine whether the human observer provides reliable testimony. Ideally, the results concerning reliability of observers generalize to other domains, even if those domains are not related to the military.

This research has a secondary objective: effective resource management. A demonstrated ability to accurately fit a model to \textit{layman-defined} flight maneuvers implies an ability to accurately fit a model to \textit{expert-defined} flight maneuvers. This is because the expert is likely to be much more consistent -- and thus her labels are much less noisy -- than the layman. This new model can be used to categorize flight maneuvers as an expert without wasting the time of an expert.

% explain research gaps

Many researchers have used flight characteristics to predict other flight characteristics, aircraft type, and even the maneuver at some point in time. However, previous research, as indicated in Section \ref{sec:related}, does not evaluate the reliability of its labels; instead, the researchers always assume their dataset is accurately labeled (when it is actually labeled; see \cite{Rodin1992}). In this research, \ac{ml} models are fit to the dataset much like in previous research, but we go further in comparing the best model's performance to that of an expert system.

% research hypotheses
% research questions

In general, it is expected that the best model will be able to successfully predict the non-expert's labels. The real significance of this research is in evaluating the correctness of the human-labeled maneuvers. It is certainly possible that the non-expert's definition of (say) turning is different from an expert's, and we wish to determine whether a model fit to the layman's definition is even useful in practical applications. Answering this question may illustrate why aircraft maneuvers labeled by non-experts are or are not reliable.

Regardless of whether the non-expert's labels are correct, accurately fitting a model to the dataset implies that a model can also be fit to an expert's labels. Such a model can reduce the use of human resources in categorizing flight data. Although the answer to this question is less impactful than the answer to the first question, it might still save the \ac{usaf} considerable time and resources in the right situation.

% overview of dataset

The \ac{afrl} maintains a flight simulator, the \ac{avas}, which generates the dataset used in this research. At any given moment, the system computes various metrics, including airspeed, angle of attack, latitude, heading, and wind angle. This reseach concerns the airplane's orientation, speed, acceleration, and altitude. The simulator is able to display all values as they change over time, and recent changes to the source code enable parameter filtering and file output.

% overview of machine learning task

To most effectively fit a model to the dataset, we train various classifiers and conduct a performance analysis of each. The software program that generates the dataset enables fully-supervised learning; this allows us to easily determine the utility of each classifier. After fitting the best possible model to the non-expert-labeled dataset, its performance is compared to that of an expert system (which labels flight maneuvers based on the roll, pitch, and yaw of the aircraft) to evaluate the reliability of the non-expert labels and the overall utility of a model fit to a human's labels.

% overview of results and implications

Results indicate that one can fit a model to a non-expert's labels with a high degree of correctness. Results also indicate that such a model can not predict an expert's labels at the same performance level. One may conclude from these results that a layman is not a reliable source of maneuver labels. However, one may also conclude that a \acl{ml} model trained on the expert's labels can likely replace the expert in labeling future observations.

% transition paragraph

In the remainder of this report, we present the research in detail. Section \ref{sec:related} examines some of the related work in current literature and explain why this work is insufficient for the research at hand. Section \ref{sec:method} describes the dataset, the model-fitting process, and the model analysis and evaluation tools. Section \ref{sec:results} discusses the results obtained. Section \ref{sec:conclusion} explains the implication of the results and possible opportunities for future research.

\end{document}
