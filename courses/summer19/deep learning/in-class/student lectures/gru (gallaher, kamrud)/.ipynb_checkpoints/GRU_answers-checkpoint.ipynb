{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding a Single Gated Recurrent Unit (GRU)\n",
    "\n",
    "## References: I HIGHLY recommend you check these out, they make the concepts easily understood in about 5 minutes\n",
    "\n",
    "### Walks through creating a GRU step by step, the author makes it super super simple to understand\n",
    "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\n",
    "\n",
    "### This video does an AMAZING job of helping you to understand what's going on with an LSTM and a GRU in a conceptual way using no math\n",
    "https://www.youtube.com/watch?v=8HyCNIVRbSU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRUs solve the vanishing gradient problem of a standard RNN through the use of update and reset gates. These gates decide what information needs to be remembered and what should be forgotten.\n",
    "\n",
    "### Here is a recurrent neural network that uses GRUs:\n",
    "![gru rnn](overview.jpg)\n",
    "\n",
    "### To understand what's going on, we're going to examine a single GRU:\n",
    "![arrows](arrows.jpg)\n",
    "\n",
    "#### We are using the following notations:\n",
    "![notations](notations.jpg)\n",
    "\n",
    "#### Additionally, $x_t$ is the current input, $h_{t-1}$ is the past state's \"hidden state\", and $h_t$ is the information that we are going to pass along to the next GRU, or the \"hidden state.\"\n",
    "\n",
    "#### I know this looks supppper complicated, but I promise it's actually simple. Let's examine it step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code\n",
    "\n",
    "# seed np\n",
    "np.random.seed( 10 )\n",
    "\n",
    "# The input, x_t, a simple 3x3 array\n",
    "\n",
    "x = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The previous hidden state, h_{t-1}\n",
    "\n",
    "h_prev = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The input weights for the update gate\n",
    "\n",
    "w_z = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The previous hidden state's weights for the update gate\n",
    "\n",
    "u_z = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The input weights for the reset gate\n",
    "\n",
    "w_r = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The previous hidden state's weights for the reset gate\n",
    "\n",
    "u_r = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The input weights\n",
    "\n",
    "w = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "# The previous hidden state's weights\n",
    "\n",
    "u = np.random.random( size=( 3, 3 ) )\n",
    "\n",
    "def sigmoid( x ):\n",
    "    \n",
    "    return ( 1 / ( 1 + math.e ** -x ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: The update gate\n",
    "## The update gate helps the model to determine how much of the past information needs to be passed along to the future.\n",
    "\n",
    "![1](1.jpg)\n",
    "\n",
    "### We start with calculating the update gate, $z_t$, for the current time step, t, using the formula:\n",
    "# $z_t = \\sigma ( W^{ (z) } x_t + U^{ (z) } h_{t-1} )$\n",
    "\n",
    "##### When the current input, $x_t$ is plugged into the GRU, it is multiplied by its own weight, $W_z$. \n",
    "##### The same occurs for the previous GRU's hidden state, $h_{t-1}$: it gets multiplied by its own weight, $U(z)$.\n",
    "##### The results of the two above operations are summed together, and then a sigmoid activation function is applied to squash the results between 0 and 1.\n",
    "\n",
    "#### We will see how the update gate, $z_t$, gets used later. For now, let's calculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6798818 , 0.61315293, 0.71439143],\n",
       "       [0.52738176, 0.61142275, 0.70887575],\n",
       "       [0.5702941 , 0.59757486, 0.5479121 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update gate calculations\n",
    "\n",
    "# Input - x\n",
    "# Input update weights - w_z\n",
    "# Previous hidden state - h_prev\n",
    "# Previous hidden state update weights - u_z\n",
    "# Sigmoid function - sigmoid( x ) returns the sigmoid of x\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Using np.multiply gives you the result of an elementwise multiplication, or:\n",
    "\n",
    "a = [ 1, 2 ]\n",
    "    [ 3, 4 ]\n",
    "    \n",
    "b = [ 4, 5 ]\n",
    "    [ 6, 7 ]\n",
    "    \n",
    "np.multiply( a, b ) = \n",
    "\n",
    "    [ ( 1 * 4 ), ( 2 * 5 ) ]\n",
    "    [ ( 3 * 6 ), ( 4 * 7 ) ]\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "weighted_update_input = np.multiply( w_z,  x )\n",
    "\n",
    "weighted_update_prev_hidden = np.multiply( h_prev, u_z )\n",
    "\n",
    "sum = weighted_update_input + weighted_update_prev_hidden\n",
    "\n",
    "z = sigmoid( sum )\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: The reset gate\n",
    "## The reset gate is used to decide how much of the past information to forget.\n",
    "\n",
    "![2](2.jpg)\n",
    "\n",
    "### Next, we need to decide what information we need to forget, or $r_t$. The formula is below\n",
    "# $r_t = \\sigma ( W^{ (r) } x_t + U^{ (r) } h_{t-1} )$\n",
    "\n",
    "##### This formula is the same as the update gate, but the difference is that we use a different set of weights, $r$. Additionally, the reset gate will be used differently that the update gate.\n",
    "##### The results of the two above operations are summed together, and then a sigmoid activation function is applied to squash the results between 0 and 1.\n",
    "\n",
    "#### We will see how the update gate, $r_t$, gets used later. For now, let's calculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53856921, 0.55478838, 0.70525626],\n",
       "       [0.61544327, 0.58843401, 0.62319941],\n",
       "       [0.52414397, 0.77631132, 0.52587335]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset gate calculations\n",
    "\n",
    "# Input - x\n",
    "# Input reset weights - w_r\n",
    "# Previous hidden state - h_prev\n",
    "# Previous hidden state reset weights - u_r\n",
    "# Sigmoid function - sigmoid( x ) returns the sigmoid of x\n",
    "\n",
    "# Using np.multiply gives you the result of an elementwise multiplication\n",
    "\n",
    "\n",
    "weighted_reset_input = np.multiply( w_r,  x )\n",
    "\n",
    "weighted_reset_prev_hidden = np.multiply( h_prev, u_r )\n",
    "\n",
    "sum = weighted_reset_input + weighted_reset_prev_hidden\n",
    "\n",
    "r = sigmoid( sum )\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Updating the current input with what we need to remember (update gate) and what we need to forget (reset gate)\n",
    "\n",
    "\n",
    "![3](3.jpg)\n",
    "\n",
    "### Now we need to decide how what we need to remember and what we need to forget from the past affects our current input:\n",
    "# $h'_t = tanh( W  x_t + r_t \\odot U  h_{t-1})$\n",
    "\n",
    "##### We accomplish the above by doing four steps:\n",
    "   1. Multiply the input $x_t$ with a weight $W$ and $h_{t-1}$ with a weight $U$.\n",
    "   2. Calculate the Hadamard (element-wise) product between the reset gate, $r_t$ and $U  h_{t-1}$. This determines what to remove from the previous steps.\n",
    "   3. Sum steps 1 and 2.\n",
    "   4. Apply a tanh function to 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31343984, 0.03451762, 0.6993215 ],\n",
       "       [0.32915124, 0.46517172, 0.22032014],\n",
       "       [0.35115165, 0.61006237, 0.15506122]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hidden state update\n",
    "\n",
    "# Input - x\n",
    "# Input weights - w\n",
    "# Previous hidden state - h_prev\n",
    "# Previous hidden state weights - u\n",
    "# Reset gate info - r\n",
    "# np.tanh( x ) returns the tanh of x\n",
    "\n",
    "# Using np.multiply gives you the result of an elementwise multiplication\n",
    "\n",
    "# Step 1\n",
    "weighted_input = np.multiply( w, x )\n",
    "weighted_prev_hidden = np.multiply( u, h_prev )\n",
    "\n",
    "# Step 2\n",
    "hadamardProduct = np.multiply( r, weighted_prev_hidden )\n",
    "\n",
    "# Step 3\n",
    "sum = weighted_input + hadamardProduct\n",
    "\n",
    "# Step 4\n",
    "hPrime = np.tanh( sum )\n",
    "\n",
    "hPrime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Output the new hidden state\n",
    "## This new hidden state, $h_t$, contains the information that we've just calculated about what is important to remember and what can be forgotten. It becomes the next GRU's $h_{t-1}$.\n",
    "\n",
    "![4](4.jpg)\n",
    "\n",
    "### Let's calculate what information to pass onto the next GRU:\n",
    "# $h_t = z_t \\odot h_{t-1} + ( 1 - z_t ) \\odot h'_t $\n",
    "\n",
    "##### We accomplish the above by doing three steps:\n",
    "   1. Apply an element wise multiplication to the update gate, $z_t$, and the previous hidden state, $h_{t-1}$.\n",
    "   2. Apply an element wise multiplication to $(1 - z_t)$ and $h'_t$.\n",
    "   3. Sum the results of 1 and 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16039843, 0.43358342, 0.88082825],\n",
       "       [0.15764513, 0.49392115, 0.64018783],\n",
       "       [0.50021194, 0.67680727, 0.23002373]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output new hidden state\n",
    "\n",
    "# Previous hidden state - h_prev\n",
    "# Previous hidden state weights - u\n",
    "# Update gate info - z\n",
    "# h' - hPrime\n",
    "\n",
    "# Using np.multiply gives you the result of an elementwise multiplication\n",
    "\n",
    "# Step 1\n",
    "step1 = np.multiply( z, h_prev)\n",
    "\n",
    "# Step 2\n",
    "step2 = np.multiply( (1-z), hPrime )\n",
    "\n",
    "# Step 3\n",
    "newHiddenState = step1 + step2\n",
    "\n",
    "newHiddenState"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
