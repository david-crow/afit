{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolutional Layers\n",
    "\n",
    "Pulled and modified from: https://github.com/ardamavi/Cat-Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, Activation, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread, imresize, toimage, imsave\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "from get_dataset import get_img, save_img\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from get_dataset import get_dataset\n",
    "from get_model import get_model, save_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------- \n",
    "**Some helper functions are written below, we don't need to edit these**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the loss function, we will use the Sorensen-Dice coefficient which measures\n",
    "the similarity between two images.\n",
    "More information can be found here: \n",
    "https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code to retrieve images and save segmented data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_img(data_path):\n",
    "    # Getting image array from path:\n",
    "    img = imread(data_path)\n",
    "    img = imresize(img, (64, 64))\n",
    "    return img\n",
    "\n",
    "def save_img(img, name='segmentated.jpg'):\n",
    "    imsave(name, img.reshape(64, 64))\n",
    "\n",
    "def get_dataset(dataset_path='Data/Train_Data'):\n",
    "    # Getting all data from data path:\n",
    "    try:\n",
    "        X = np.load('Data/npy_train_data/X.npy')\n",
    "        Y = np.load('Data/npy_train_data/Y.npy')\n",
    "    except:\n",
    "        inputs_path = dataset_path+'/input'\n",
    "        images = listdir(inputs_path) # Geting images\n",
    "        X = []\n",
    "        Y = []\n",
    "        for img in images:\n",
    "            img_path = inputs_path+'/'+img\n",
    "\n",
    "            x_img = get_img(img_path).astype('float32').reshape(64, 64, 3)\n",
    "            x_img /= 255.\n",
    "\n",
    "            y_img = get_img(img_path.replace('input/', 'mask/mask_')).astype('float32').reshape(64, 64, 1)\n",
    "            y_img /= 255.\n",
    "\n",
    "            X.append(x_img)\n",
    "            Y.append(y_img)\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        # Create dateset:\n",
    "        if not os.path.exists('Data/npy_train_data/'):\n",
    "            os.makedirs('Data/npy_train_data/')\n",
    "        np.save('Data/npy_train_data/X.npy', X)\n",
    "        np.save('Data/npy_train_data/Y.npy', Y)\n",
    "    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    return X, X_test, Y, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-built function to save the model's weights\n",
    "\"\"\"\n",
    "def save_model(model):\n",
    "    if not os.path.exists('Data/Model/'):\n",
    "        os.makedirs('Data/Model/')\n",
    "    model_json = model.to_json()\n",
    "    with open(\"Data/Model/model.json\", \"w\") as model_file:\n",
    "        model_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"Data/Model/weights.h5\")\n",
    "    print('Model and weights saved')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "### Student code below.\n",
    "We will build a basic conv to deconv network for image segmentation use. \n",
    "\n",
    "**Model Architecture, build the network like this:**   \n",
    "  \n",
    "Input Data Shape: 64x64x3\n",
    "  \n",
    "Convolutional Layer. 32 kernels with shape: 3x3. Strides: 1x1\n",
    "  \n",
    "Activation Function: ReLu\n",
    "  \n",
    "Convolutional Layer. 64 kernels with shape: 3x3. Strides: 1x1\n",
    "  \n",
    "Activation Function: ReLu\n",
    "  \n",
    "**Transpose Convolutional Layer. 64 kernels with shape: 3x3. Strides: 1x1**\n",
    "  \n",
    "Activation Function: ReLu\n",
    "  \n",
    "Merge Layer\n",
    "  \n",
    "**Transpose Convolutional Layer. 1 kernel with shape: 3x3. Strides: 1x1**\n",
    "  \n",
    "Activation Function: Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gumda\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model and weights saved\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "####### Student code: modify this below #################\n",
    "#########################################################\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    ########### Images are 64x64 RGB\n",
    "    inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "    ####### First convolution layer\n",
    "    conv_1 = Conv2D(1, (3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    act_1 = Activation('relu')(conv_1)\n",
    "\n",
    "    ###### Second convolution layer\n",
    "    conv_2 = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(act_1)\n",
    "    act_2 = Activation('relu')(conv_2)\n",
    "\n",
    "######################################################\n",
    "\n",
    "#Edits go here\n",
    "#First deconv layer. Use keras Conv2DTranspose with similar inputs to the Conv2D layer\n",
    "\n",
    "#deconv_1 = Conv2DTranspose(filters, kernel_size, strides=(1, 1), padding='valid' or 'same')\n",
    "\n",
    "    \n",
    "    act_3 = Activation('relu')(deconv_1)\n",
    "######################################################\n",
    "    \n",
    "    ##### Now merge layer 1 with layer 3\n",
    "    merge_1 = concatenate([act_3, act_1], axis=3)\n",
    "    \n",
    "###################################################\n",
    "\n",
    "#Second edits go here\n",
    "#Second Deconv layer, Use keras Conv2DTranspose with similar inputs to the Conv2D layer\n",
    "#deconv_2 = Conv2DTranspose(filters, kernel_size, strides=(1, 1), padding='valid' or 'same')\n",
    "#this one is after the merge layer, so be sure to use (merge_1)\n",
    "\n",
    "    \n",
    "    \n",
    "    act_4 = Activation('relu')(deconv_2)\n",
    "##################################################\n",
    "    \n",
    "    ##### Compile the model\n",
    "    model = Model(inputs=[inputs], outputs=[act_4])\n",
    "    model.compile(optimizer='adadelta', loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     save_model(get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](ConvDeconv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now train the model for 50 epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 9 samples\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.4574 - dice_coef: 0.4574 - val_loss: -0.7484 - val_dice_coef: 0.7484\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.7795 - val_dice_coef: 0.7795\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8759 - dice_coef: 0.8759 - val_loss: -0.7883 - val_dice_coef: 0.7883\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.7915 - val_dice_coef: 0.7915\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8831 - dice_coef: 0.8831 - val_loss: -0.7938 - val_dice_coef: 0.7938\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.7946 - val_dice_coef: 0.7946\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8840 - dice_coef: 0.8840 - val_loss: -0.7946 - val_dice_coef: 0.7946\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.7961 - val_dice_coef: 0.7961\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.7971 - val_dice_coef: 0.7971\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.7983 - val_dice_coef: 0.7983\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.7973 - val_dice_coef: 0.7973\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.7967 - val_dice_coef: 0.7967\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.7963 - val_dice_coef: 0.7963\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.7945 - val_dice_coef: 0.7945\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.7940 - val_dice_coef: 0.7940\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.7937 - val_dice_coef: 0.7937\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.7918 - val_dice_coef: 0.7918\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 17ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.7888 - val_dice_coef: 0.7888\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 18ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.7869 - val_dice_coef: 0.7869\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.7832 - val_dice_coef: 0.7832\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.8999 - dice_coef: 0.8999 - val_loss: -0.7785 - val_dice_coef: 0.7785\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.7717 - val_dice_coef: 0.7717\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.7587 - val_dice_coef: 0.7587\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 20ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.7531 - val_dice_coef: 0.7531\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.7468 - val_dice_coef: 0.7468\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9281 - dice_coef: 0.9281 - val_loss: -0.7398 - val_dice_coef: 0.7398\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9280 - dice_coef: 0.9280 - val_loss: -0.7228 - val_dice_coef: 0.7228\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9276 - dice_coef: 0.9276 - val_loss: -0.7120 - val_dice_coef: 0.7120\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9297 - dice_coef: 0.9297 - val_loss: -0.6704 - val_dice_coef: 0.6704\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.6596 - val_dice_coef: 0.6596\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9368 - dice_coef: 0.9368 - val_loss: -0.6468 - val_dice_coef: 0.6468\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9360 - dice_coef: 0.9360 - val_loss: -0.6297 - val_dice_coef: 0.6297\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9370 - dice_coef: 0.9370 - val_loss: -0.6317 - val_dice_coef: 0.6317\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9644 - dice_coef: 0.9644 - val_loss: -0.7227 - val_dice_coef: 0.7227\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 20ms/step - loss: -0.9438 - dice_coef: 0.9438 - val_loss: -0.6849 - val_dice_coef: 0.6849\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9365 - dice_coef: 0.9365 - val_loss: -0.6767 - val_dice_coef: 0.6767\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9497 - dice_coef: 0.9497 - val_loss: -0.6264 - val_dice_coef: 0.6264\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9498 - dice_coef: 0.9498 - val_loss: -0.6419 - val_dice_coef: 0.6419\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9491 - dice_coef: 0.9491 - val_loss: -0.6397 - val_dice_coef: 0.6397\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9606 - dice_coef: 0.9606 - val_loss: -0.6229 - val_dice_coef: 0.6229\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9538 - dice_coef: 0.9538 - val_loss: -0.5676 - val_dice_coef: 0.5676\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9440 - dice_coef: 0.9440 - val_loss: -0.6036 - val_dice_coef: 0.6036\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9457 - dice_coef: 0.9457 - val_loss: -0.6009 - val_dice_coef: 0.6009\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9651 - dice_coef: 0.9651 - val_loss: -0.6193 - val_dice_coef: 0.6193\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9646 - dice_coef: 0.9646 - val_loss: -0.6203 - val_dice_coef: 0.6203\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 20ms/step - loss: -0.9704 - dice_coef: 0.9704 - val_loss: -0.6539 - val_dice_coef: 0.6539\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 20ms/step - loss: -0.9591 - dice_coef: 0.9591 - val_loss: -0.6735 - val_dice_coef: 0.6735\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9724 - dice_coef: 0.9724 - val_loss: -0.6358 - val_dice_coef: 0.6358\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 19ms/step - loss: -0.9710 - dice_coef: 0.9710 - val_loss: -0.6395 - val_dice_coef: 0.6395\n",
      "Model and weights saved\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "################ change this to True to train!\n",
    "traincats = False\n",
    "############################################\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 5\n",
    "\n",
    "if traincats == True:\n",
    "\n",
    "    def train_model(model, X, X_test, Y, Y_test):\n",
    "        if not os.path.exists('Data/Checkpoints/'):\n",
    "            os.makedirs('Data/Checkpoints/')\n",
    "        checkpoints = []\n",
    "        checkpoints.append(ModelCheckpoint('Data/Checkpoints/best_weights.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1))\n",
    "        checkpoints.append(TensorBoard(log_dir='Data/Checkpoints/./logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None))\n",
    "    \n",
    "        model.fit(X, Y, batch_size=batch_size, epochs=epochs, validation_data=(X_test, Y_test), shuffle=True, callbacks=checkpoints)\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def main():\n",
    "        X, X_test, Y, Y_test = get_dataset()\n",
    "        model = get_model()\n",
    "        model = train_model(model, X, X_test, Y, Y_test)\n",
    "        save_model(model)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now pick a cat to segment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentated image saved as segmentated.jpg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Go into Data/Train_Data/input/ and pick your favorite cat image.\n",
    "Then segment it by changing the number in cat.##.jpg below to the one you want.\n",
    "Try a few different ones and compare outputs!\n",
    "\"\"\"\n",
    "\n",
    "if traincats == True:\n",
    "    %run -i \"predict.py\" \"Data/Train_Data/input/cat.39.jpg\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
