{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolutional Layers\n",
    "\n",
    "Pulled and modified from: https://github.com/ardamavi/Cat-Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, Activation, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread, imresize, toimage, imsave\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "from get_dataset import get_img, save_img\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from get_dataset import get_dataset\n",
    "from get_model import get_model, save_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------- \n",
    "**Some helper functions are written below, we don't need to edit these**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the loss function, we will use the Sorensen-Dice coefficient which measures\n",
    "the similarity between two images.\n",
    "More information can be found here: \n",
    "https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code to retrieve images and save segmented data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_img(data_path):\n",
    "    # Getting image array from path:\n",
    "    img = imread(data_path)\n",
    "    img = imresize(img, (64, 64))\n",
    "    return img\n",
    "\n",
    "def save_img(img, name='segmentated.jpg'):\n",
    "    imsave(name, img.reshape(64, 64))\n",
    "\n",
    "def get_dataset(dataset_path='Data/Train_Data'):\n",
    "    # Getting all data from data path:\n",
    "    try:\n",
    "        X = np.load('Data/npy_train_data/X.npy')\n",
    "        Y = np.load('Data/npy_train_data/Y.npy')\n",
    "    except:\n",
    "        inputs_path = dataset_path+'/input'\n",
    "        images = listdir(inputs_path) # Geting images\n",
    "        X = []\n",
    "        Y = []\n",
    "        for img in images:\n",
    "            img_path = inputs_path+'/'+img\n",
    "\n",
    "            x_img = get_img(img_path).astype('float32').reshape(64, 64, 3)\n",
    "            x_img /= 255.\n",
    "\n",
    "            y_img = get_img(img_path.replace('input/', 'mask/mask_')).astype('float32').reshape(64, 64, 1)\n",
    "            y_img /= 255.\n",
    "\n",
    "            X.append(x_img)\n",
    "            Y.append(y_img)\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        # Create dateset:\n",
    "        if not os.path.exists('Data/npy_train_data/'):\n",
    "            os.makedirs('Data/npy_train_data/')\n",
    "        np.save('Data/npy_train_data/X.npy', X)\n",
    "        np.save('Data/npy_train_data/Y.npy', Y)\n",
    "    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    return X, X_test, Y, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-built function to save the model's weights\n",
    "\"\"\"\n",
    "def save_model(model):\n",
    "    if not os.path.exists('Data/Model/'):\n",
    "        os.makedirs('Data/Model/')\n",
    "    model_json = model.to_json()\n",
    "    with open(\"Data/Model/model.json\", \"w\") as model_file:\n",
    "        model_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"Data/Model/weights.h5\")\n",
    "    print('Model and weights saved')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "### Student Modified code below.\n",
    "We will build a basic conv to deconv network for image segmentation use. \n",
    "\n",
    "**Model Architecture, build the network like this:**   \n",
    "Input Data Shape: 64x64x3\n",
    "  \n",
    "Convolutional Layer. 32 kernels with shape: 3x3. Strides: 1x1\n",
    "  \n",
    "Activation Function: ReLu\n",
    "  \n",
    "Convolutional Layer. 64 kernels with shape: 3x3. Strides: 1x1\n",
    "  \n",
    "Activation Function: ReLu\n",
    "  \n",
    "**Transpose Convolutional Layer. 64 kernels with shape: 3x3. Strides: 1x1**\n",
    "  \n",
    "Activation Function: ReLu\n",
    "  \n",
    "Merge Layer\n",
    "  \n",
    "**Transpose Convolutional Layer. 1 kernel with shape: 3x3. Strides: 1x1**\n",
    "  \n",
    "Activation Function: Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gumda\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model and weights saved\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "####### Student code: modify this below #################\n",
    "#########################################################\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    ########### Images are 64x64 RGB\n",
    "    inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "    ####### First convolution layer\n",
    "    conv_1 = Conv2D(1, (3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    act_1 = Activation('relu')(conv_1)\n",
    "\n",
    "    ###### Second convolution layer\n",
    "    conv_2 = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(act_1)\n",
    "    act_2 = Activation('relu')(conv_2)\n",
    "\n",
    "######################################################\n",
    "\n",
    "#Edits go here\n",
    "#First deconv layer. Use keras Conv2DTranspose with similar inputs to the Conv2D layer\n",
    "\n",
    "#deconv_1 = Conv2DTranspose(filters, kernel_size, strides=(1, 1), \n",
    "#    padding='valid' or 'same')\n",
    "\n",
    "    \n",
    "    deconv_1 = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same')(act_2)\n",
    "    act_3 = Activation('relu')(deconv_1)\n",
    "######################################################\n",
    "    \n",
    "    ##### Now merge layer 1 with layer 3\n",
    "    merge_1 = concatenate([act_3, act_1], axis=3)\n",
    "    \n",
    "###################################################\n",
    "\n",
    "#Second edits go here\n",
    "#Second Deconv layer, Use keras Conv2DTranspose with similar inputs to the Conv2D layer\n",
    "#deconv_2 = Conv2DTranspose(filters, kernel_size, strides=(1, 1), \n",
    "#    padding='valid' or 'same')\n",
    "\n",
    "    \n",
    "    deconv_2 = Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same')(merge_1)\n",
    "    act_4 = Activation('relu')(deconv_2)\n",
    "##################################################\n",
    "    \n",
    "    ##### Compile the model\n",
    "    model = Model(inputs=[inputs], outputs=[act_4])\n",
    "    model.compile(optimizer='adadelta', loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     save_model(get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](ConvDeconv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now train the model for 50 epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################ change this to True to train!\n",
    "traincats = False\n",
    "##################\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 5\n",
    "\n",
    "if traincats == True:\n",
    "\n",
    "    def train_model(model, X, X_test, Y, Y_test):\n",
    "        if not os.path.exists('Data/Checkpoints/'):\n",
    "            os.makedirs('Data/Checkpoints/')\n",
    "        checkpoints = []\n",
    "        checkpoints.append(ModelCheckpoint('Data/Checkpoints/best_weights.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1))\n",
    "        checkpoints.append(TensorBoard(log_dir='Data/Checkpoints/./logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None))\n",
    "    \n",
    "        model.fit(X, Y, batch_size=batch_size, epochs=epochs, validation_data=(X_test, Y_test), shuffle=True, callbacks=checkpoints)\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def main():\n",
    "        X, X_test, Y, Y_test = get_dataset()\n",
    "        model = get_model()\n",
    "        model = train_model(model, X, X_test, Y, Y_test)\n",
    "        save_model(model)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentated image saved as segmentated.jpg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Go into Data/Train_Data/input/ and pick your favorite cat image.\n",
    "Then segment it by changing the number in cat.##.jpg below to the one you want.\n",
    "Try a few different ones and compare outputs!\n",
    "\"\"\"\n",
    "\n",
    "if traincats == True:\n",
    "    %run -i \"predict.py\" \"Data/Train_Data/input/cat.39.jpg\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
