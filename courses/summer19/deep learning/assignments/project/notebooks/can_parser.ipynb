{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CAN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Capture</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Time</th>\n",
       "      <th>ArbID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Data</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.546464e+09</td>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.546464e+09</td>\n",
       "      <td>708</td>\n",
       "      <td>8</td>\n",
       "      <td>0000001A0480016D</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.546464e+09</td>\n",
       "      <td>705</td>\n",
       "      <td>8</td>\n",
       "      <td>08FCEA214AA700CB</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.546464e+09</td>\n",
       "      <td>708</td>\n",
       "      <td>8</td>\n",
       "      <td>0000001A0480016D</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.546464e+09</td>\n",
       "      <td>720</td>\n",
       "      <td>8</td>\n",
       "      <td>0000080030000012</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Capture  Vehicle          Time ArbID  DLC              Data    Make  \\\n",
       "0        1        1  1.546464e+09   722    1                00  Toyota   \n",
       "1        1        1  1.546464e+09   708    8  0000001A0480016D  Toyota   \n",
       "2        1        1  1.546464e+09   705    8  08FCEA214AA700CB  Toyota   \n",
       "3        1        1  1.546464e+09   708    8  0000001A0480016D  Toyota   \n",
       "4        1        1  1.546464e+09   720    8  0000080030000012  Toyota   \n",
       "\n",
       "    Model  Year  \n",
       "0  Tacoma  2008  \n",
       "1  Tacoma  2008  \n",
       "2  Tacoma  2008  \n",
       "3  Tacoma  2008  \n",
       "4  Tacoma  2008  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 50.41 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = None\n",
    "\n",
    "data_directory = \"/Users/david/Documents/masters/thesis/data\"\n",
    "\n",
    "if not os.path.exists(os.path.join(data_directory, \"all_data.csv\")):\n",
    "    print(\"Reading CSV file 1...\")\n",
    "    ornl_data = pd.read_csv(os.path.join(data_directory, \"ornl-data\", \"can_data.csv\"),\n",
    "        dtype={\"captureid\": int, \"vehicle_id\": int, \"ts\": float, \"arbitration_id\": object, \n",
    "               \"dlc\": int, \"data\": object, \"make\": object, \"model\": object, \"year\": int})\n",
    "\n",
    "    print(\"Reading CSV file 2...\")\n",
    "    stone_data = pd.read_csv(os.path.join(data_directory, \"stone-data\", \"can_data.csv\"),\n",
    "        dtype={\"captureid\": int, \"vehicle_id\": int, \"Titsme\": float, \"arbitration_id\": object, \n",
    "               \"dlc\": int, \"data\": object, \"make\": object, \"model\": object, \"year\": int})\n",
    "\n",
    "    # rename the columns\n",
    "    ornl_data.columns = [\"Capture\", \"Vehicle\", \"Time\", \"ArbID\", \"DLC\", \"Data\", \"Make\", \"Model\", \"Year\"]\n",
    "    stone_data.columns = [\"Capture\", \"Vehicle\", \"Time\", \"ArbID\", \"DLC\", \"Data\", \"Make\", \"Model\", \"Year\"]\n",
    "    \n",
    "    # combine the dataframes\n",
    "    print(\"Combining dataframes...\")\n",
    "    data = pd.concat([ornl_data, stone_data])\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    print(\"Writing to \" + os.path.join(data_directory, \"all_data.csv\"))\n",
    "    data.to_csv(os.path.join(data_directory, \"all_data.csv\"), index=False)\n",
    "\n",
    "else:\n",
    "    print(\"File already exists!\")\n",
    "    data = pd.read_csv(os.path.join(data_directory, \"all_data.csv\"),\n",
    "        dtype={\"Capture\": int, \"Vehicle\": int, \"Time\": float, \"ArbID\": object, \n",
    "               \"DLC\": int, \"Data\": object, \"Make\": object, \"Model\": object, \"Year\": int})\n",
    "\n",
    "display(data.head(5))\n",
    "end = time.time()\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 165.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# how long does this take?\n",
    "start = time.time()\n",
    "\n",
    "# number of bytes in each snapshot\n",
    "chunk_size = 1024\n",
    "\n",
    "# minimum number of snapshots for each arbID\n",
    "min_snaps = 1\n",
    "\n",
    "# used to build a dataframe\n",
    "captures = []\n",
    "vehicles = []\n",
    "arbIDs = []\n",
    "num_bytes = []\n",
    "num_snaps = []\n",
    "valid = []\n",
    "\n",
    "# for each capture...\n",
    "for i in np.sort(data[\"Capture\"].unique()):\n",
    "    capture = data[data[\"Capture\"] == i]\n",
    "    vehicle = capture[\"Vehicle\"].iloc[0]\n",
    "    \n",
    "    # for each arbID for capture i...\n",
    "    for j in capture[\"ArbID\"].unique():\n",
    "        arbID = capture[capture[\"ArbID\"] == j]\n",
    "        bytes_count = np.sum(arbID[\"DLC\"])\n",
    "        \n",
    "        captures.append(i)\n",
    "        vehicles.append(vehicle)\n",
    "        arbIDs.append(j)\n",
    "        num_bytes.append(bytes_count)\n",
    "        num_snaps.append(bytes_count // chunk_size)\n",
    "                \n",
    "        # every vehicle/arbID combo needs at least one picture\n",
    "        valid.append(\"yes\" if bytes_count >= chunk_size * min_snaps else \"no\")\n",
    "\n",
    "# build a dataframe\n",
    "metadata = pd.DataFrame(\n",
    "    np.hstack((\n",
    "        np.array(vehicles).reshape(-1,1),\n",
    "        np.array(captures).reshape(-1,1),\n",
    "        np.array(arbIDs).reshape(-1,1),\n",
    "        np.array(num_bytes).reshape(-1,1),\n",
    "        np.array(num_snaps).reshape(-1,1),\n",
    "        np.array(valid).reshape(-1,1)\n",
    "    )),\n",
    "    \n",
    "    columns = [\"Vehicle\", \"Capture\", \"ArbID\", \"Bytes\", \"Snapshots\", \"Valid?\"]\n",
    ")\n",
    "\n",
    "# update the datatypes\n",
    "for col in metadata.columns.drop([\"ArbID\", \"Valid?\"]):\n",
    "    metadata[col] = pd.to_numeric(metadata[col])\n",
    "\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Capture</th>\n",
       "      <th>ArbID</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Snapshots</th>\n",
       "      <th>Valid?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1217</td>\n",
       "      <td>7464</td>\n",
       "      <td>7</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>440192</td>\n",
       "      <td>429</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>440192</td>\n",
       "      <td>429</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>705</td>\n",
       "      <td>214256</td>\n",
       "      <td>209</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>708</td>\n",
       "      <td>288792</td>\n",
       "      <td>282</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vehicle  Capture ArbID   Bytes  Snapshots Valid?\n",
       "0        1        1  1217    7464          7    yes\n",
       "1        1        1  2015  440192        429    yes\n",
       "2        1        1  2024  440192        429    yes\n",
       "3        1        1   705  214256        209    yes\n",
       "4        1        1   708  288792        282    yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012 valid ArbIDs from 20 vehicles\n",
      "164 invalid ArbIDs from 12 vehicles\n",
      "297253 snapshots\n"
     ]
    }
   ],
   "source": [
    "# sort and show the dataframe\n",
    "metadata = metadata.sort_values(by=[\"Vehicle\", \"Capture\", \"ArbID\"]).reset_index(drop=True)\n",
    "display(metadata.head(5))\n",
    "\n",
    "valid = metadata[metadata[\"Valid?\"] == \"yes\"]\n",
    "invalid = metadata[metadata[\"Valid?\"] == \"no\"]\n",
    "\n",
    "valid_arbs = 0\n",
    "for i in valid[\"Vehicle\"].unique():\n",
    "    valid_arbs += len(valid[valid[\"Vehicle\"] == i][\"ArbID\"].unique())\n",
    "\n",
    "invalid_arbs = 0\n",
    "for i in invalid[\"Vehicle\"].unique():\n",
    "    invalid_arbs += len(invalid[invalid[\"Vehicle\"] == i][\"ArbID\"].unique())\n",
    "\n",
    "print(\"{} valid ArbIDs from {} vehicles\".format(\n",
    "    valid_arbs,\n",
    "    len(valid[\"Vehicle\"].unique())\n",
    "))\n",
    "\n",
    "print(\"{} invalid ArbIDs from {} vehicles\".format(\n",
    "    invalid_arbs,\n",
    "    len(invalid[\"Vehicle\"].unique())\n",
    "))\n",
    "\n",
    "print(\"{} snapshots\".format(np.sum(metadata[metadata[\"Valid?\"] == \"yes\"][\"Snapshots\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 & 8 & 4440 & 1.49 \\% \\\\\n",
      "2 & 47 & 6895 & 2.32 \\% \\\\\n",
      "3 & 49 & 141847 & 47.72 \\% \\\\\n",
      "4 & 103 & 14633 & 4.92 \\% \\\\\n",
      "5 & 112 & 43377 & 14.59 \\% \\\\\n",
      "6 & 79 & 9511 & 3.20 \\% \\\\\n",
      "7 & 124 & 35142 & 11.82 \\% \\\\\n",
      "8 & 35 & 5018 & 1.69 \\% \\\\\n",
      "9 & 21 & 8211 & 2.76 \\% \\\\\n",
      "101 & 29 & 4102 & 1.38 \\% \\\\\n",
      "102 & 50 & 1824 & 0.61 \\% \\\\\n",
      "103 & 62 & 1757 & 0.59 \\% \\\\\n",
      "104 & 78 & 2182 & 0.73 \\% \\\\\n",
      "105 & 24 & 3791 & 1.28 \\% \\\\\n",
      "106 & 28 & 1695 & 0.57 \\% \\\\\n",
      "107 & 42 & 2198 & 0.74 \\% \\\\\n",
      "108 & 38 & 3020 & 1.02 \\% \\\\\n",
      "109 & 26 & 2553 & 0.86 \\% \\\\\n",
      "110 & 19 & 2974 & 1.00 \\% \\\\\n",
      "111 & 38 & 2083 & 0.70 \\% \\\\\n"
     ]
    }
   ],
   "source": [
    "total_snaps = np.sum(valid[\"Snapshots\"])\n",
    "\n",
    "for i in valid[\"Vehicle\"].unique():\n",
    "    temp = valid[valid[\"Vehicle\"] == i]\n",
    "    num_arbs = len(temp[\"ArbID\"].unique())\n",
    "    num_snaps = np.sum(temp[\"Snapshots\"])\n",
    "    \n",
    "    print(\"{} & {} & {} & {:.2f} \\% \\\\\\\\\".format(i, num_arbs, num_snaps, 100. * num_snaps / total_snaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting capture 1 (1/45)...\n",
      "Starting capture 2 (2/45)...\n",
      "Starting capture 3 (3/45)...\n",
      "Starting capture 4 (4/45)...\n",
      "Starting capture 5 (5/45)...\n",
      "Starting capture 6 (6/45)...\n",
      "Starting capture 7 (7/45)...\n",
      "Starting capture 8 (8/45)...\n",
      "Starting capture 9 (9/45)...\n",
      "Starting capture 10 (10/45)...\n",
      "Starting capture 11 (11/45)...\n",
      "Starting capture 12 (12/45)...\n",
      "Starting capture 13 (13/45)...\n",
      "Starting capture 14 (14/45)...\n",
      "Starting capture 15 (15/45)...\n",
      "Starting capture 16 (16/45)...\n",
      "Starting capture 17 (17/45)...\n",
      "Starting capture 18 (18/45)...\n",
      "Starting capture 19 (19/45)...\n",
      "Starting capture 20 (20/45)...\n",
      "Starting capture 21 (21/45)...\n",
      "Starting capture 22 (22/45)...\n",
      "Starting capture 23 (23/45)...\n",
      "Starting capture 24 (24/45)...\n",
      "Starting capture 25 (25/45)...\n",
      "Starting capture 26 (26/45)...\n",
      "Starting capture 27 (27/45)...\n",
      "Starting capture 28 (28/45)...\n",
      "Starting capture 29 (29/45)...\n",
      "Starting capture 30 (30/45)...\n",
      "Starting capture 31 (31/45)...\n",
      "Starting capture 32 (32/45)...\n",
      "Starting capture 46 (33/45)...\n",
      "Starting capture 52 (34/45)...\n",
      "Starting capture 101 (35/45)...\n",
      "Starting capture 102 (36/45)...\n",
      "Starting capture 103 (37/45)...\n",
      "Starting capture 104 (38/45)...\n",
      "Starting capture 105 (39/45)...\n",
      "Starting capture 106 (40/45)...\n",
      "Starting capture 107 (41/45)...\n",
      "Starting capture 108 (42/45)...\n",
      "Starting capture 109 (43/45)...\n",
      "Starting capture 110 (44/45)...\n",
      "Starting capture 111 (45/45)...\n"
     ]
    }
   ],
   "source": [
    "filename = \"../snapshots/unfiltered_snapshots.csv\"\n",
    "\n",
    "# delete any snapshot files that already exist\n",
    "# we do this because we open the file with append,\n",
    "# but we don't want to append to previously-created files\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "# how long does this take?\n",
    "start = time.time()\n",
    "\n",
    "# make the big file\n",
    "f = open(filename, \"w+\")\n",
    "f.write(\"Vehicle,Capture\")\n",
    "for i in range(1024):\n",
    "    f.write(\",Data \" + str(i + 1))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "# for every capture (each is tied to a vehicle)...\n",
    "for idx, cap in enumerate(data[\"Capture\"].unique()):\n",
    "    print(\"Starting capture {} ({}/{})...\".format(cap, idx + 1, len(valid[\"Capture\"].unique())))\n",
    "    capture = data[data[\"Capture\"] == cap]\n",
    "    vehicle = capture[\"Vehicle\"].iloc[0]\n",
    "    \n",
    "    # join all hex data values into one big string\n",
    "    can_data = capture[\"Data\"].str.cat(sep=\"\")\n",
    "    \n",
    "    # split big string into array of hex bytes\n",
    "    can_data = [can_data[i:i+2] for i in range(0, len(can_data), 2)]\n",
    "    \n",
    "    # convert each hex byte into a three-digit integer\n",
    "    for i, d in enumerate(can_data):\n",
    "        can_data[i] = str(int(d, 16)).zfill(3)\n",
    "    \n",
    "    # write every set of <chunk_size> bytes to the file\n",
    "    for i in range(0, len(can_data) - chunk_size, chunk_size):\n",
    "        f.write(\"{},{},{}\\n\".format(vehicle, cap, \",\".join(can_data[i:i+chunk_size])))\n",
    "\n",
    "f.close()\n",
    "elapsed = time.time() - start\n",
    "print(\"Elapsed time: {:.2f} seconds ({:.2f} minutes)\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the snapshots to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = \"../snapshots/snapshots.csv\"\n",
    "\n",
    "# delete any snapshot files that already exist\n",
    "# we do this because we open the file with append,\n",
    "# but we don't want to append to previously-created files\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "# how long does this take?\n",
    "start = time.time()\n",
    "\n",
    "# make the big file\n",
    "f = open(filename, \"w+\")\n",
    "f.write(\"Vehicle,Capture,ArbID\")\n",
    "for i in range(1024):\n",
    "    f.write(\",Data \" + str(i + 1))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "# we only want ArbIDs with at least <min_snaps> snapshots\n",
    "valid = metadata[metadata[\"Valid?\"] == \"yes\"]\n",
    "\n",
    "# for every capture (each is tied to a vehicle)...\n",
    "for count, capture in enumerate(valid[\"Capture\"].unique()):\n",
    "    print(\"Starting capture {} ({}/{})...\".format(capture, count + 1, len(valid[\"Capture\"].unique())))\n",
    "    capture = valid[valid[\"Capture\"] == capture]\n",
    "    vehicle = capture[\"Vehicle\"].iloc[0]\n",
    "    \n",
    "    # for every arbID in this capture...\n",
    "    for _, row in capture.iterrows():\n",
    "        # we only care about one arbID from one capture of one vehicle\n",
    "        can = data[data[\"Capture\"] == row[\"Capture\"]]\n",
    "        can = can[can[\"ArbID\"] == row[\"ArbID\"]]\n",
    "        \n",
    "        # join all hex data values into one big string\n",
    "        can_data = can[\"Data\"].str.cat(sep=\"\")\n",
    "        \n",
    "        # split big string into array of hex bytes\n",
    "        can_data = [can_data[i:i+2] for i in range(0, len(can_data), 2)]\n",
    "        \n",
    "        # convert each hex byte into a three-digit integer\n",
    "        for i, d in enumerate(can_data):\n",
    "            can_data[i] = str(int(d, 16)).zfill(3)\n",
    "        \n",
    "        # write every set of <chunk_size> bytes to the file\n",
    "        for i in range(0, len(can_data) - chunk_size, chunk_size):\n",
    "            f.write(\"{},{},{},{}\\n\".format(\n",
    "                row[\"Vehicle\"],\n",
    "                row[\"Capture\"],\n",
    "                row[\"ArbID\"],\n",
    "                \",\".join(can_data[i:i+chunk_size])\n",
    "            ))\n",
    "\n",
    "f.close()\n",
    "elapsed = time.time() - start\n",
    "print(\"Elapsed time: {:.2f} seconds ({:.2f} minutes)\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
